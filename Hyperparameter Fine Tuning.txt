Fine Tuning
    - Encontrar o conjunto de parâmetros que maximiza o aprendizado do modelo
    
    
 Existem 3 estratégias de Fine Tuning
 1. Random Search
     a. Define valores para cada um dos hiperparâmetros aleatoriamente.
    - ex: n_estimetors, eta, subsample, max_deph
   Vantagens:
   -Muito rápido relacionada aos outros
   
   desvantagens:
   -Pode pegar o mesmo conjunto de valores por ser algo aleatório
   -Pode nunca conseguir encontar o valor que maximiza o melhor aprendizado do modelo
      
   
 2. Grid Search
     a. Define todas as combinações possíveis de valores que os hiperparâmetros podem assumir
     Testa todas as variavéis e combinações possiveis
     Vantagem:
     -Vai encontrar o melhor parâmetro ou chegar próximo dele
     
     desvantagem:
     -leva muito tempo
     
 3. Bayesian Search
     a. Define os valores para os hiperparâmetros seguindo a teoria de Bayes.
     
    P(A|B) = P(B|A)P(A)/P(B)
    supondo que o A é o erro
    A: Erro
    
    Supondo B os valores dos parâmetros
    
    B:Parâmetros(n_estimetors....)
    
    P(Erro|Param)  =  (P(Param|Erro) P(Erro))/ P(Param)
    
    
    Posterior =( Likelihood Prior)/ Evidence
    
    
    Vantagens:
    - Define os valores para os hoperparâmetros baseado em aprendizados passados
    - mais rápido que o grid, porem mais lendo que o random
    
    - mais complexo de aprender


